{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.0 64-bit ('PyCapacitron': conda)",
   "metadata": {
    "interpreter": {
     "hash": "04ae8f06ef2069926318fb21ef951f475c5c242dceb49e7faf78b2393ada81ce"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n > Using model: Tacotron\n > Setting up Audio Processor...\n | > sample_rate:24000\n | > resample:False\n | > num_mels:80\n | > min_level_db:-100\n | > frame_shift_ms:None\n | > frame_length_ms:None\n | > ref_level_db:20\n | > fft_size:1024\n | > power:1.5\n | > preemphasis:0.0\n | > griffin_lim_iters:60\n | > signal_norm:True\n | > symmetric_norm:True\n | > mel_fmin:95.0\n | > mel_fmax:12000.0\n | > spec_gain:20.0\n | > stft_pad_mode:reflect\n | > max_norm:4.0\n | > clip_norm:True\n | > do_trim_silence:True\n | > trim_db:60\n | > do_sound_norm:False\n | > stats_path:None\n | > hop_length:256\n | > win_length:1024\n17100\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# this code is copied from: https://github.com/mozilla/TTS/blob/master/notebooks/Benchmark.ipynb\n",
    "#\n",
    "\n",
    "# TTS\n",
    "tts_pretrained_model = '/home/big-boy/Models/Blizzard/blizzard-gts-March-15-2021_05+24PM-b4248b0/best_model.pth.tar'\n",
    "tts_pretrained_model_config = '/home/big-boy/projects/Capacitron/TTS/tts/configs/gst_blizzard.json'\n",
    "\n",
    "import io\n",
    "import torch \n",
    "import time\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from matplotlib import pylab as plt\n",
    "import IPython\n",
    "\n",
    "%pylab inline\n",
    "rcParams[\"figure.figsize\"] = (16,5)\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "from TTS.tts.models.tacotron import Tacotron \n",
    "from TTS.tts.layers import *\n",
    "from TTS.tts.utils.data import *\n",
    "from TTS.utils.audio import AudioProcessor\n",
    "from TTS.utils.io import load_config \n",
    "from TTS.tts.utils.generic_utils import setup_model\n",
    "\n",
    "from TTS.tts.utils.text import text_to_sequence\n",
    "from TTS.tts.utils.synthesis import synthesis\n",
    "from TTS.tts.utils.visual import visualize\n",
    "from TTS.tts.utils.text.symbols import symbols, phonemes\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "def tts(model, text, CONFIG, use_cuda, ap, use_gl, speaker_id=None, figures=True):\n",
    "    t_1 = time.time()\n",
    "    waveform, alignment, decoder_output, postnet_output, stop_tokens, inputs = synthesis(model, text, CONFIG, use_cuda, ap, truncated=True, enable_eos_bos_chars=CONFIG.enable_eos_bos_chars)\n",
    "    if CONFIG.model == \"Tacotron\" and not use_gl:\n",
    "        postnet_output = ap.out_linear_to_mel(postnet_output.T).T\n",
    "    if not use_gl:\n",
    "        waveform = wavernn.generate(torch.FloatTensor(postnet_output.T).unsqueeze(0).cuda(), batched=batched_wavernn, target=11000, overlap=550)\n",
    "\n",
    "    print(\" >  Run-time: {}\".format(time.time() - t_1))\n",
    "    if figures:                                                                                                         \n",
    "        visualize(alignment, postnet_output, stop_tokens, text, ap.hop_length, CONFIG, mel_spec)                                                                       \n",
    "    # IPython.display.display(Audio(waveform, rate=CONFIG.audio['sample_rate']))  \n",
    "    # OUT_FOLDER = 'out/'\n",
    "    # file_name = 'yolo.wav'\n",
    "    # os.makedirs(OUT_FOLDER, exist_ok=True)\n",
    "    # #file_name = text.replace(\" \", \"_\").replace(\".\",\"\") + \".wav\"\n",
    "    # out_path = os.path.join(OUT_FOLDER, file_name)\n",
    "    # ap.save_wav(waveform, out_path)\n",
    "    print(waveform)\n",
    "    return alignment, postnet_output, stop_tokens, waveform\n",
    "  \n",
    "use_cuda = True\n",
    "batched_wavernn = True\n",
    "\n",
    "# initialize TTS\n",
    "CONFIG = load_config(tts_pretrained_model_config)\n",
    "# load the model\n",
    "num_chars = len(phonemes) if CONFIG.use_phonemes else len(symbols)\n",
    "model = setup_model(num_chars, 1, CONFIG)\n",
    "# load the audio processor\n",
    "ap = AudioProcessor(**CONFIG.audio)         \n",
    "# load model state\n",
    "if use_cuda:\n",
    "    cp = torch.load(tts_pretrained_model)\n",
    "else:\n",
    "    cp = torch.load(tts_pretrained_model, map_location=lambda storage, loc: storage)\n",
    "\n",
    "# load the model\n",
    "model.load_state_dict(cp['model'])\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "model.eval()\n",
    "print(cp['step'])\n",
    "model.decoder.max_decoder_steps = 2000\n",
    "\n",
    "# # initialize WaveRNN\n",
    "# VOCODER_CONFIG = load_config(wavernn_pretrained_model_config)\n",
    "# with localimport('/content/WaveRNN') as _importer:\n",
    "#   from models.wavernn import Model\n",
    "# bits = 10\n",
    "\n",
    "# wavernn = Model(\n",
    "#         rnn_dims=512,\n",
    "#         fc_dims=512,\n",
    "#         mode=\"mold\",\n",
    "#         pad=2,\n",
    "#         upsample_factors=VOCODER_CONFIG.upsample_factors,  # set this depending on dataset\n",
    "#         feat_dims=VOCODER_CONFIG.audio[\"num_mels\"],\n",
    "#         compute_dims=128,\n",
    "#         res_out_dims=128,\n",
    "#         res_blocks=10,\n",
    "#         hop_length=ap.hop_length,\n",
    "#         sample_rate=ap.sample_rate,\n",
    "#     ).cuda()\n",
    "# check = torch.load(wavernn_pretrained_model)\n",
    "# wavernn.load_state_dict(check['model'])\n",
    "# if use_cuda:\n",
    "#     wavernn.cuda()\n",
    "# wavernn.eval()\n",
    "# print(check['step'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   | > Decoder stopped with 'max_decoder_steps\n",
      " >  Run-time: 2.962998867034912\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "SENTENCE = 'Bill got in the habit of asking himself “Is that thought true?” And if he wasn’t absolutely certain it was, he just let it go.'\n",
    "align, spec, stop_tokens, wav = tts(model, SENTENCE, CONFIG, use_cuda, ap, speaker_id=0, use_gl=True, figures=False)"
   ]
  }
 ]
}