{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "152d7c66-5c77-419f-949d-64c76eee88ab",
   "metadata": {},
   "source": [
    "# 訓練済みVITSモデルによる推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce802a89-48eb-46b6-8a6a-e466f7e051f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from TTS.tts.models.vits import Vits, VitsAudioConfig\n",
    "from TTS.tts.configs.vits_config import VitsArgs, VitsConfig\n",
    "from TTS.utils.audio import AudioProcessor\n",
    "from TTS.tts.utils.text.tokenizer import TTSTokenizer\n",
    "from TTS.tts.utils.speakers import SpeakerManager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1797b6b-5e56-4c41-b4b4-de0aec171b36",
   "metadata": {},
   "source": [
    "## モデルのロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5cde9f-688e-4bb6-994b-5c8c23af78f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_config = VitsAudioConfig(\n",
    "    sample_rate=22050, win_length=1024, hop_length=256, num_mels=80, mel_fmin=0, mel_fmax=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f07bad-5cb8-4233-95f4-57491ad81431",
   "metadata": {},
   "outputs": [],
   "source": [
    "vitsArgs = VitsArgs(\n",
    "    use_speaker_embedding=True,\n",
    ")\n",
    "\n",
    "config = VitsConfig(\n",
    "    model_args=vitsArgs,\n",
    "    audio=audio_config,\n",
    "    run_name=\"vits_vctk\",\n",
    "    batch_size=16,\n",
    "    eval_batch_size=16,\n",
    "    batch_group_size=5,\n",
    "    num_loader_workers=4,\n",
    "    num_eval_loader_workers=4,\n",
    "    run_eval=True,\n",
    "    test_delay_epochs=-1,\n",
    "    epochs=1000,\n",
    "    text_cleaner=\"english_cleaners\",\n",
    "    use_phonemes=True,\n",
    "    phoneme_language=\"en\",\n",
    "    compute_input_seq_cache=True,\n",
    "    print_step=25,\n",
    "    print_eval=False,\n",
    "    mixed_precision=True,\n",
    "    max_text_len=325,  # change this if you have a larger VRAM than 16GB\n",
    "    cudnn_benchmark=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b998b0-4b61-4d1d-8f66-aacf2a890cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = AudioProcessor.init_from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64bc27c-4321-40bf-b8a1-e773a86fffd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245de41e-49f5-4297-83e4-1b6ada4b30ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer, config = TTSTokenizer.init_from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca171e8-e3ce-465c-90d1-36a4ec1b0614",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_file_path = \"../recipes/vctk/vits/vits_vctk-November-18-2022_12+10PM-05b4ee16/speakers.pth\"\n",
    "speaker_manager = SpeakerManager(speaker_id_file_path=id_file_path)\n",
    "print(speaker_manager.num_speakers)\n",
    "print(speaker_manager.speaker_names)\n",
    "print(speaker_manager.get_speakers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a673d6fe-9c52-47e0-b87b-0fc3f2563ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\")\n",
    "model = Vits(config, ap, tokenizer, speaker_manager).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02bd9e9-a841-4f97-a6e5-33d21c292a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"../recipes/vctk/vits/vits_vctk-November-18-2022_12+10PM-05b4ee16/checkpoint_230000.pth\"\n",
    "model.load_checkpoint(config, checkpoint_path, eval=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a50f3a-b405-470b-829c-af6eccd6ba21",
   "metadata": {},
   "source": [
    "## テキストからの推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b5f8f8-3d17-4600-98ff-fc5e4e39a589",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = \"This cake is great. It's so delicious and moist.\"\n",
    "# raw_text = \"Many animals\"\n",
    "token_ids = tokenizer.text_to_ids(raw_text)\n",
    "token_ids = torch.Tensor(token_ids).long().to(device)\n",
    "token_ids = token_ids.unsqueeze(0)\n",
    "token_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab6d3da-e41a-4451-82b9-aa9f56b14391",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker2id = speaker_manager.get_speakers()\n",
    "print(speaker2id[\"VCTK_p260\"])\n",
    "print(speaker2id[\"VCTK_p310\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68158526-c53d-4b5f-9fb4-bfe1dbebf2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_ids = torch.Tensor([speaker2id[\"VCTK_p310\"]]).long().to(device)\n",
    "speaker_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aca0b9c-0ede-4914-9843-82f7c8ebd4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.inference(token_ids, aux_input={\"speaker_ids\": speaker_ids})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429139bf-30da-4e4a-a5e0-0a36c216b321",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in outputs.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd948f9-e051-4c72-a552-b36964f159eb",
   "metadata": {},
   "source": [
    "## 合成音"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3d4da8-55f3-4da1-9cd4-f7086bb2a32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import display, Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58233069-686d-4d73-baac-6672054112ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform = outputs[\"model_outputs\"].squeeze().cpu().numpy()\n",
    "waveform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1a38cd-2e3b-420f-9745-87834cc67242",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(waveform);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12de0f38-54cb-44d7-b52b-1614130defcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Audio(waveform, rate=config.audio.sample_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c91c8a0-8d1d-4df9-a9d2-2070784016f4",
   "metadata": {},
   "source": [
    "## アラインメントの可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c013673e-5249-438d-b3b7-40f0856e7eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TTS.tts.utils.visual import plot_alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d548099-b0cb-4422-9d5a-6de2556c12f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "alignments = outputs[\"alignments\"]\n",
    "alignments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e2b782-017d-487e-9434-852991ad24c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "align_img = alignments[0].data.cpu().numpy().T\n",
    "align_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f64308a-4aca-4d39-b820-5fe9e6eab297",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_alignment(align_img, output_fig=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ef518d-2ebf-404c-b49a-48175856191f",
   "metadata": {},
   "source": [
    "## 時間長"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a480424-2087-4697-8c95-5b20b9265b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc122ef-6dbe-4eff-97be-0bf0bd954112",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs[\"durations\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c7fa67-52b3-4fc8-8b09-38334d328d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs[\"durations\"].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2765db52-5952-4340-9396-4572784f96e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "200960 / 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb54d61-b6ac-4868-8196-6abdff1f471b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# durationsの単位はフレーム\n",
    "# 合計すると音声のフレーム長に一致する\n",
    "outputs[\"durations\"].squeeze().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ae1267-0816-4a82-bbc3-ef4eeb3a1e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [tokenizer.characters.id_to_char(x) for x in token_ids[0].cpu().numpy()]\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b331aa-ce04-451b-8028-ead982c6c5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "durations = outputs[\"durations\"].squeeze().cpu().numpy() * config.audio.hop_length\n",
    "len(durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b11558-713e-43b4-bd5c-e3984757c620",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81299d8c-cd74-4562-858b-f088172b0cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = list(np.cumsum(durations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1af3bd5-31d0-4e33-877f-b7d5757d388b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(positions), len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6478ad-cee8-4220-92f4-d7eb84ea4c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24, 8))\n",
    "plt.plot(waveform)\n",
    "for (i, x), token in zip(enumerate(positions), tokens):\n",
    "    if token == \"<BLNK>\":\n",
    "        token = \"B\"\n",
    "    plt.axvline(x, color=\"r\")\n",
    "    plt.text(x - 250, 0.0, token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1443fc6-dbb0-4e93-9acc-8d79b22a5530",
   "metadata": {},
   "source": [
    "## 訓練内の話者間での音声変換\n",
    "\n",
    "- https://jaywalnut310.github.io/vits-demo/index.html#vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1647089-e460-4ce9-9338-7c5b4a7e27a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "p260_wav = ap.load_wav(\"../recipes/vctk/VCTK/wav48_silence_trimmed/p260/p260_040_mic1.flac\")\n",
    "p310_wav = ap.load_wav(\"../recipes/vctk/VCTK/wav48_silence_trimmed/p310/p310_020_mic1.flac\")\n",
    "\n",
    "display(Audio(data=p260_wav, rate=ap.sample_rate))\n",
    "display(Audio(data=p310_wav, rate=ap.sample_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6b4511-1786-4a16-9b82-47e492210733",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker2id = speaker_manager.get_speakers()\n",
    "print(speaker2id[\"VCTK_p260\"])\n",
    "print(speaker2id[\"VCTK_p310\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f86cfb-3daa-440b-9092-3716000b0923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p260 => p310\n",
    "# coqui-ttsでは reference = source の意味\n",
    "reference_wav = torch.from_numpy(p260_wav).float().unsqueeze(0).to(device)\n",
    "speaker_id = torch.Tensor([speaker2id[\"VCTK_p310\"]]).long().to(device)\n",
    "reference_speaker_id = torch.Tensor([speaker2id[\"VCTK_p260\"]]).long().to(device)\n",
    "\n",
    "converted_wav = model.inference_voice_conversion(\n",
    "    reference_wav,\n",
    "    speaker_id=speaker_id,\n",
    "    reference_speaker_id=reference_speaker_id)\n",
    "converted_wav = converted_wav.squeeze().cpu().numpy()\n",
    "converted_wav.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaf10d4-0fa8-4893-91bf-670fd805bcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(converted_wav);\n",
    "display(Audio(data=converted_wav, rate=ap.sample_rate))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "2504cb0e3e4224dfb4bb19413b576a0bc8ab50ac2e8cfa3fbf1f5f00bce6c9fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
